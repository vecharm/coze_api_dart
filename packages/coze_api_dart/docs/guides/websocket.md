# WebSocket å®æ—¶é€šä¿¡æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»å¦‚ä½•ä½¿ç”¨ Coze API Dart SDK çš„ WebSocket åŠŸèƒ½å®ç°å®æ—¶è¯­éŸ³å¯¹è¯ã€è¯­éŸ³åˆæˆå’Œè¯­éŸ³è¯†åˆ«ã€‚

## ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [WebSocket Chat](#websocket-chat)
- [WebSocket è¯­éŸ³åˆæˆ](#websocket-è¯­éŸ³åˆæˆ)
- [WebSocket è¯­éŸ³è¯†åˆ«](#websocket-è¯­éŸ³è¯†åˆ«)
- [äº‹ä»¶å¤„ç†](#äº‹ä»¶å¤„ç†)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## æ¦‚è¿°

WebSocket æä¾›å…¨åŒå·¥é€šä¿¡é€šé“ï¼Œé€‚åˆå®æ—¶äº¤äº’åœºæ™¯ï¼š

- **å®æ—¶å¯¹è¯**: ä½å»¶è¿Ÿçš„è¯­éŸ³/æ–‡æœ¬å¯¹è¯
- **è¯­éŸ³åˆæˆ**: å®æ—¶æ–‡æœ¬è½¬è¯­éŸ³
- **è¯­éŸ³è¯†åˆ«**: å®æ—¶è¯­éŸ³è½¬æ–‡æœ¬

### ç‰¹ç‚¹

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| å®æ—¶æ€§ | æ¯«ç§’çº§å»¶è¿Ÿ |
| åŒå‘é€šä¿¡ | åŒæ—¶å‘é€å’Œæ¥æ”¶ |
| æµå¼å¤„ç† | è¾¹æ¥æ”¶è¾¹å¤„ç† |
| ä½å¸¦å®½ | æ¯” HTTP è½®è¯¢æ›´é«˜æ•ˆ |

---

## WebSocket Chat

### åŸºç¡€ç”¨æ³•

```dart
import 'package:coze_api_dart/coze_api_dart.dart';

void main() async {
  final client = CozeAPI(
    token: 'your_pat_token',
    baseURL: CozeURLs.comBaseURL,
  );

  // åˆ›å»º WebSocket è¿æ¥
  final ws = await client.websocket.chat.create(
    CreateChatWsRequest(
      botId: 'your_bot_id',
      voiceId: 'your_voice_id',  // å¯é€‰ï¼šè¯­éŸ³ ID
    ),
  );

  // ç›‘å¬äº‹ä»¶
  ws.events.listen((event) {
    switch (event.eventType) {
      case WebsocketsEventType.conversationChatCreated:
        print('å¯¹è¯å·²åˆ›å»º');
        break;

      case WebsocketsEventType.conversationMessageDelta:
        // æ–‡æœ¬å¢é‡
        stdout.write(event.data['content']);
        break;

      case WebsocketsEventType.conversationAudioDelta:
        // éŸ³é¢‘æ•°æ®
        final audioData = base64Decode(event.data['audio']);
        playAudio(audioData);  // æ’­æ”¾éŸ³é¢‘
        break;

      case WebsocketsEventType.error:
        print('é”™è¯¯: ${event.data}');
        break;
    }
  });

  // å‘é€æ–‡æœ¬æ¶ˆæ¯
  ws.sendText('ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±');

  // å‘é€éŸ³é¢‘ï¼ˆè¯­éŸ³è¾“å…¥ï¼‰
  final audioData = await recordAudio();
  ws.sendAudio(audioData);
}
```

### å®Œæ•´å®æ—¶å¯¹è¯ç¤ºä¾‹

```dart
import 'dart:async';
import 'dart:convert';
import 'dart:typed_data';
import 'package:coze_api_dart/coze_api_dart.dart';

class RealtimeChat {
  final CozeAPI client;
  WebSocketChatConnection? _connection;
  final _audioBuffer = BytesBuilder();

  RealtimeChat({required this.client});

  Future<void> connect({
    required String botId,
    String? voiceId,
    String? conversationId,
  }) async {
    _connection = await client.websocket.chat.create(
      CreateChatWsRequest(
        botId: botId,
        voiceId: voiceId,
        conversationId: conversationId,
      ),
    );

    _connection!.events.listen(
      _handleEvent,
      onError: (error) => print('WebSocket é”™è¯¯: $error'),
      onDone: () => print('WebSocket è¿æ¥å…³é—­'),
    );
  }

  void _handleEvent(ChatWsEvent event) {
    switch (event.eventType) {
      case WebsocketsEventType.conversationChatCreated:
        print('âœ… å¯¹è¯å·²åˆ›å»º: ${event.data['id']}');
        break;

      case WebsocketsEventType.conversationMessageCreated:
        print('ğŸ¤– Bot å¼€å§‹å›å¤...');
        break;

      case WebsocketsEventType.conversationMessageDelta:
        final content = event.data['content'] as String?;
        if (content != null) {
          stdout.write(content);
        }
        break;

      case WebsocketsEventType.conversationMessageCompleted:
        print('\nâœ… æ¶ˆæ¯å®Œæˆ');
        break;

      case WebsocketsEventType.conversationAudioDelta:
        // æ¥æ”¶éŸ³é¢‘å¢é‡
        final audioBase64 = event.data['audio'] as String?;
        if (audioBase64 != null) {
          final audioData = base64Decode(audioBase64);
          _audioBuffer.add(audioData);
        }
        break;

      case WebsocketsEventType.conversationAudioCompleted:
        // éŸ³é¢‘å®Œæˆï¼Œæ’­æ”¾
        final completeAudio = _audioBuffer.toBytes();
        _audioBuffer.clear();
        playAudio(completeAudio);
        break;

      case WebsocketsEventType.inputAudioBufferSpeechStarted:
        print('ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹');
        break;

      case WebsocketsEventType.inputAudioBufferSpeechStopped:
        print('ğŸ¤ è¯­éŸ³ç»“æŸ');
        break;

      case WebsocketsEventType.error:
        print('âŒ é”™è¯¯: ${event.data['error']}');
        break;

      default:
        print('äº‹ä»¶: ${event.eventType}');
    }
  }

  void sendText(String text) {
    _connection?.sendText(text);
  }

  void sendAudio(Uint8List audioData) {
    _connection?.sendAudio(audioData);
  }

  void close() {
    _connection?.close();
    _connection = null;
  }
}

void main() async {
  final client = CozeAPI(
    token: 'your_pat_token',
    baseURL: CozeURLs.comBaseURL,
  );

  final chat = RealtimeChat(client: client);

  await chat.connect(
    botId: 'your_bot_id',
    voiceId: 'your_voice_id',
  );

  // å‘é€æ¶ˆæ¯
  chat.sendText('ä½ å¥½ï¼');

  // ä¿æŒç¨‹åºè¿è¡Œ
  await Future.delayed(Duration(minutes: 5));

  chat.close();
}
```

---

## WebSocket è¯­éŸ³åˆæˆ

### å®æ—¶æ–‡æœ¬è½¬è¯­éŸ³

```dart
import 'dart:convert';
import 'package:coze_api_dart/coze_api_dart.dart';

void main() async {
  final client = CozeAPI(
    token: 'your_pat_token',
    baseURL: CozeURLs.comBaseURL,
  );

  // åˆ›å»ºè¯­éŸ³åˆæˆ WebSocket
  final speech = await client.websocket.audio.speech.create(
    CreateSpeechRequest(
      entityType: 'bot',
      entityId: 'your_bot_id',
    ),
  );

  final audioChunks = <Uint8List>[];

  // ç›‘å¬éŸ³é¢‘è¾“å‡º
  speech.events.listen((event) {
    switch (event.eventType) {
      case WebsocketsEventType.conversationAudioCompleted:
        // æ¥æ”¶éŸ³é¢‘æ•°æ®
        final audioBase64 = event.data['audio'] as String?;
        if (audioBase64 != null) {
          audioChunks.add(base64Decode(audioBase64));
        }
        break;

      case WebsocketsEventType.conversationTtsMessageUpdate:
        // TTS æ–‡æœ¬æ›´æ–°
        print('åˆæˆæ–‡æœ¬: ${event.data['text']}');
        break;

      case WebsocketsEventType.conversationChatCreated:
        print('è¯­éŸ³åˆæˆä¼šè¯å·²åˆ›å»º');
        break;

      case WebsocketsEventType.error:
        print('é”™è¯¯: ${event.data}');
        break;
    }
  });

  // æ–¹å¼1ï¼šç›´æ¥å‘é€å®Œæ•´æ–‡æœ¬
  speech.sendTextUpdate('ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªè¯­éŸ³åˆæˆæµ‹è¯•ã€‚');

  // æ–¹å¼2ï¼šæµå¼å‘é€æ–‡æœ¬ï¼ˆæ‰“å­—æœºæ•ˆæœï¼‰
  final text = 'è¿™æ˜¯é€å­—å‘é€çš„æ–‡æœ¬';
  for (final char in text.split('')) {
    speech.appendTextBuffer(char);
    await Future.delayed(Duration(milliseconds: 100));
  }
  speech.completeTextBuffer();

  // ç­‰å¾…éŸ³é¢‘æ¥æ”¶å®Œæˆ
  await Future.delayed(Duration(seconds: 3));

  // åˆå¹¶å¹¶æ’­æ”¾éŸ³é¢‘
  final completeAudio = Uint8List.fromList(
    audioChunks.expand((e) => e).toList(),
  );
  await playAudio(completeAudio);

  speech.close();
}
```

### è¯­éŸ³åˆæˆäº‹ä»¶å¤„ç†

```dart
class SpeechSynthesizer {
  final WebSocketSpeechConnection _connection;
  final _audioBuffer = BytesBuilder();
  Completer<Uint8List>? _completer;

  SpeechSynthesizer(this._connection) {
    _connection.events.listen(_handleEvent);
  }

  void _handleEvent(SpeechEvent event) {
    switch (event.eventType) {
      case WebsocketsEventType.conversationChatCreated:
        print('ğŸµ è¯­éŸ³åˆæˆå·²å¯åŠ¨');
        break;

      case WebsocketsEventType.conversationAudioCompleted:
        final audioBase64 = event.data['audio'] as String?;
        if (audioBase64 != null) {
          _audioBuffer.add(base64Decode(audioBase64));
        }
        break;

      case WebsocketsEventType.conversationTtsMessageUpdate:
        // å¯ä»¥åœ¨è¿™é‡Œè·å–åˆæˆè¿›åº¦
        final text = event.data['text'] as String?;
        print('ğŸ“ åˆæˆè¿›åº¦: $text');
        break;

      case WebsocketsEventType.conversationChatCompleted:
        // æ‰€æœ‰éŸ³é¢‘æ¥æ”¶å®Œæˆ
        final completeAudio = _audioBuffer.toBytes();
        _audioBuffer.clear();
        _completer?.complete(completeAudio);
        break;

      case WebsocketsEventType.error:
        _completer?.completeError(event.data['error']);
        break;

      default:
        break;
    }
  }

  Future<Uint8List> synthesize(String text) async {
    _completer = Completer<Uint8List>();

    // å‘é€æ–‡æœ¬
    _connection.sendTextUpdate(text);

    // ç­‰å¾…å®Œæˆ
    return await _completer!.future;
  }

  void close() => _connection.close();
}
```

---

## WebSocket è¯­éŸ³è¯†åˆ«

### å®æ—¶è¯­éŸ³è½¬æ–‡æœ¬

```dart
import 'dart:typed_data';
import 'package:coze_api_dart/coze_api_dart.dart';

void main() async {
  final client = CozeAPI(
    token: 'your_pat_token',
    baseURL: CozeURLs.comBaseURL,
  );

  // åˆ›å»ºè¯­éŸ³è¯†åˆ« WebSocket
  final transcription = await client.websocket.audio.transcriptions.create(
    CreateTranscriptionsRequest(
      entityType: 'bot',
      entityId: 'your_bot_id',
    ),
  );

  final recognizedText = StringBuffer();

  // ç›‘å¬è¯†åˆ«ç»“æœ
  transcription.events.listen((event) {
    switch (event.eventType) {
      case WebsocketsEventType.conversationSpeechToTextUpdated:
        // å¢é‡è¯†åˆ«ç»“æœ
        final delta = event.data['delta'] as String?;
        if (delta != null) {
          recognizedText.write(delta);
          print('è¯†åˆ«ä¸­: $recognizedText');
        }
        break;

      case WebsocketsEventType.conversationSpeechToTextCompleted:
        // æœ€ç»ˆè¯†åˆ«ç»“æœ
        final text = event.data['text'] as String?;
        print('âœ… æœ€ç»ˆè¯†åˆ«: $text');
        recognizedText.clear();
        break;

      case WebsocketsEventType.inputAudioBufferCompleted:
        print('ğŸ¤ éŸ³é¢‘è¾“å…¥å®Œæˆ');
        break;

      case WebsocketsEventType.inputAudioBufferCleared:
        print('ğŸ—‘ï¸ éŸ³é¢‘ç¼“å†²åŒºå·²æ¸…é™¤');
        recognizedText.clear();
        break;

      case WebsocketsEventType.error:
        print('âŒ é”™è¯¯: ${event.data}');
        break;
    }
  });

  // æ¨¡æ‹ŸéŸ³é¢‘è¾“å…¥ï¼ˆå®é™…åº”ä»éº¦å…‹é£è·å–ï¼‰
  final audioStream = getMicrophoneStream();

  await for (final audioChunk in audioStream) {
    // å‘é€éŸ³é¢‘æ•°æ®
    transcription.appendAudioBuffer(audioChunk);
  }

  // æ ‡è®°éŸ³é¢‘è¾“å…¥å®Œæˆ
  transcription.completeAudioBuffer();

  // ç­‰å¾…è¯†åˆ«å®Œæˆ
  await Future.delayed(Duration(seconds: 2));

  transcription.close();
}

// æ¨¡æ‹Ÿéº¦å…‹é£éŸ³é¢‘æµ
Stream<Uint8List> getMicrophoneStream() async* {
  // å®é™…å®ç°åº”ä½¿ç”¨ record æˆ– mic_stream ç­‰åŒ…
  // è¿™é‡Œä»…ä½œç¤ºä¾‹
  for (int i = 0; i < 100; i++) {
    yield Uint8List(1024);  // éŸ³é¢‘æ•°æ®å—
    await Future.delayed(Duration(milliseconds: 20));
  }
}
```

### è¯­éŸ³è¯†åˆ«æ§åˆ¶å™¨

```dart
class SpeechRecognizer {
  WebSocketTranscriptionsConnection? _connection;
  final _recognizedText = StringBuffer();
  final _textController = StreamController<String>.broadcast();

  Stream<String> get textStream => _textController.stream;

  Future<void> start({
    required String entityType,
    required String entityId,
  }) async {
    final client = CozeAPI(/* ... */);

    _connection = await client.websocket.audio.transcriptions.create(
      CreateTranscriptionsRequest(
        entityType: entityType,
        entityId: entityId,
      ),
    );

    _connection!.events.listen(_handleEvent);
  }

  void _handleEvent(TranscriptionEvent event) {
    switch (event.eventType) {
      case WebsocketsEventType.conversationSpeechToTextUpdated:
        final delta = event.data['delta'] as String? ?? '';
        _recognizedText.write(delta);
        _textController.add(_recognizedText.toString());
        break;

      case WebsocketsEventType.conversationSpeechToTextCompleted:
        final text = event.data['text'] as String? ?? '';
        _textController.add('[å®Œæˆ] $text');
        _recognizedText.clear();
        break;

      default:
        break;
    }
  }

  void sendAudio(Uint8List audioData) {
    _connection?.appendAudioBuffer(audioData);
  }

  void stop() {
    _connection?.completeAudioBuffer();
  }

  void clear() {
    _connection?.clearAudioBuffer();
    _recognizedText.clear();
  }

  void dispose() {
    _connection?.close();
    _textController.close();
  }
}
```

---

## äº‹ä»¶å¤„ç†

### æ‰€æœ‰ WebSocket äº‹ä»¶ç±»å‹

```dart
enum WebsocketsEventType {
  // å¯¹è¯ç›¸å…³
  conversationChatCreated,      // å¯¹è¯åˆ›å»º
  conversationChatInProgress,   // å¯¹è¯è¿›è¡Œä¸­
  conversationChatCompleted,    // å¯¹è¯å®Œæˆ
  conversationChatFailed,       // å¯¹è¯å¤±è´¥
  conversationChatRequiresAction, // éœ€è¦æ“ä½œ

  // æ¶ˆæ¯ç›¸å…³
  conversationMessageCreated,   // æ¶ˆæ¯åˆ›å»º
  conversationMessageDelta,     // æ¶ˆæ¯å¢é‡
  conversationMessageCompleted, // æ¶ˆæ¯å®Œæˆ
  conversationMessageInProgress, // æ¶ˆæ¯è¿›è¡Œä¸­

  // éŸ³é¢‘ç›¸å…³
  conversationAudioDelta,       // éŸ³é¢‘å¢é‡
  conversationAudioCompleted,   // éŸ³é¢‘å®Œæˆ
  conversationTtsMessageUpdate, // TTS æ›´æ–°

  // è¯­éŸ³è¯†åˆ«ç›¸å…³
  conversationSpeechToTextUpdated,   // STT æ›´æ–°
  conversationSpeechToTextCompleted, // STT å®Œæˆ

  // è¾“å…¥éŸ³é¢‘ç›¸å…³
  inputAudioBufferCompleted,    // éŸ³é¢‘è¾“å…¥å®Œæˆ
  inputAudioBufferCleared,      // éŸ³é¢‘ç¼“å†²åŒºæ¸…é™¤
  inputAudioBufferSpeechStarted, // æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹
  inputAudioBufferSpeechStopped, // æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ

  // é”™è¯¯
  error,
  done,
}
```

### äº‹ä»¶æ•°æ®ç»“æ„

```dart
// å¯¹è¯åˆ›å»ºäº‹ä»¶
event.data = {
  'id': 'conversation_id',
  'bot_id': 'bot_id',
  'created_at': 1234567890,
};

// æ¶ˆæ¯å¢é‡äº‹ä»¶
event.data = {
  'id': 'message_id',
  'role': 'assistant',
  'content': 'å¢é‡æ–‡æœ¬',
  'content_type': 'text',
};

// éŸ³é¢‘å¢é‡äº‹ä»¶
event.data = {
  'audio': 'base64_encoded_audio_data',
  'format': 'pcm',
  'sample_rate': 24000,
};

// è¯­éŸ³è¯†åˆ«æ›´æ–°äº‹ä»¶
event.data = {
  'delta': 'å¢é‡æ–‡æœ¬',
  'text': 'å½“å‰å®Œæ•´æ–‡æœ¬',
};

// é”™è¯¯äº‹ä»¶
event.data = {
  'error': 'é”™è¯¯ä¿¡æ¯',
  'code': 'error_code',
};
```

---

## æœ€ä½³å®è·µ

### 1. è¿æ¥ç®¡ç†

```dart
class WebSocketManager {
  WebSocketConnection? _connection;
  Timer? _pingTimer;
  bool _isReconnecting = false;

  Future<void> connect() async {
    _connection = await createConnection();

    // è®¾ç½®å¿ƒè·³
    _pingTimer = Timer.periodic(Duration(seconds: 30), (_) {
      _connection?.ping();
    });

    // ç›‘å¬è¿æ¥å…³é—­
    _connection!.events.listen(
      (event) {},
      onDone: () {
        _pingTimer?.cancel();
        if (!_isReconnecting) {
          _reconnect();
        }
      },
    );
  }

  Future<void> _reconnect() async {
    _isReconnecting = true;
    print('è¿æ¥æ–­å¼€ï¼Œæ­£åœ¨é‡è¿...');

    await Future.delayed(Duration(seconds: 3));
    await connect();

    _isReconnecting = false;
  }

  void disconnect() {
    _pingTimer?.cancel();
    _connection?.close();
  }
}
```

### 2. éŸ³é¢‘æ•°æ®å¤„ç†

```dart
class AudioProcessor {
  // éŸ³é¢‘æ ¼å¼è½¬æ¢
  Uint8List convertToPCM16(Uint8List input, int sampleRate) {
    // å®ç°éŸ³é¢‘æ ¼å¼è½¬æ¢
    // ä¾‹å¦‚ï¼šä» Float32 è½¬æ¢ä¸º Int16
    return input;
  }

  // éŸ³é¢‘ç¼“å†²
  final _buffer = BytesBuilder();
  static const chunkSize = 3200;  // 100ms @ 16kHz, 16bit, mono

  void addAudio(Uint8List data) {
    _buffer.add(data);

    // å‘é€å›ºå®šå¤§å°çš„å—
    while (_buffer.length >= chunkSize) {
      final chunk = Uint8List.sublistView(
        Uint8List.fromList(_buffer.toBytes()),
        0,
        chunkSize,
      );
      sendAudioChunk(chunk);

      // ç§»é™¤å·²å‘é€çš„æ•°æ®
      final remaining = _buffer.toBytes().sublist(chunkSize);
      _buffer.clear();
      _buffer.add(remaining);
    }
  }

  void flush() {
    if (_buffer.isNotEmpty) {
      sendAudioChunk(_buffer.toBytes());
      _buffer.clear();
    }
  }
}
```

### 3. é”™è¯¯å¤„ç†

```dart
void handleWebSocketError(dynamic error) {
  if (error is WebSocketException) {
    print('WebSocket é”™è¯¯: ${error.message}');

    switch (error.code) {
      case 'CONNECTION_REFUSED':
        print('è¿æ¥è¢«æ‹’ç»ï¼Œæ£€æŸ¥ç½‘ç»œ');
        break;
      case 'AUTHENTICATION_FAILED':
        print('è®¤è¯å¤±è´¥ï¼Œæ£€æŸ¥ä»¤ç‰Œ');
        break;
      case 'RATE_LIMITED':
        print('è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œç¨åé‡è¯•');
        break;
      default:
        print('æœªçŸ¥é”™è¯¯: ${error.code}');
    }
  } else {
    print('å…¶ä»–é”™è¯¯: $error');
  }
}
```

### 4. Flutter é›†æˆ

```dart
class VoiceChatPage extends StatefulWidget {
  @override
  _VoiceChatPageState createState() => _VoiceChatPageState();
}

class _VoiceChatPageState extends State<VoiceChatPage> {
  RealtimeChat? _chat;
  bool _isConnected = false;
  bool _isListening = false;
  String _status = 'ç‚¹å‡»å¼€å§‹';

  @override
  void initState() {
    super.initState();
    _initChat();
  }

  Future<void> _initChat() async {
    final client = CozeAPI(
      token: 'your_pat_token',
      baseURL: CozeURLs.comBaseURL,
    );

    _chat = RealtimeChat(client: client);

    await _chat!.connect(
      botId: 'your_bot_id',
      voiceId: 'your_voice_id',
    );

    setState(() {
      _isConnected = true;
      _status = 'å·²è¿æ¥ï¼Œç‚¹å‡»è¯´è¯';
    });
  }

  void _toggleListening() {
    setState(() {
      _isListening = !_isListening;
      _status = _isListening ? 'æ­£åœ¨å¬...' : 'å·²æš‚åœ';
    });

    if (_isListening) {
      _startRecording();
    } else {
      _stopRecording();
    }
  }

  void _startRecording() {
    // å¼€å§‹å½•éŸ³å¹¶å‘é€åˆ° WebSocket
    // ä½¿ç”¨ record åŒ…æˆ–å…¶ä»–å½•éŸ³åº“
  }

  void _stopRecording() {
    // åœæ­¢å½•éŸ³
  }

  @override
  void dispose() {
    _chat?.close();
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(title: Text('è¯­éŸ³å¯¹è¯')),
      body: Center(
        child: Column(
          mainAxisAlignment: MainAxisAlignment.center,
          children: [
            Text(_status),
            SizedBox(height: 20),
            FloatingActionButton(
              onPressed: _isConnected ? _toggleListening : null,
              child: Icon(_isListening ? Icons.mic : Icons.mic_none),
            ),
          ],
        ),
      ),
    );
  }
}
```

---

## å¸¸è§é—®é¢˜

### Q: WebSocket è¿æ¥å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

A: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š

```dart
// 1. æ£€æŸ¥ä»¤ç‰Œ
if (!isPersonalAccessToken(token)) {
  print('ä»¤ç‰Œæ ¼å¼ä¸æ­£ç¡®');
}

// 2. æ£€æŸ¥ç½‘ç»œ
final client = CozeAPI(
  token: token,
  baseURL: CozeURLs.comBaseURL,
  config: CozeConfig(
    timeout: Duration(seconds: 30),
    enableLogging: true,  // å¯ç”¨æ—¥å¿—æŸ¥çœ‹è¯¦æƒ…
  ),
);

// 3. æ£€æŸ¥ Bot ID
// ç¡®ä¿ Bot å·²å‘å¸ƒä¸”æœ‰ WebSocket æƒé™
```

### Q: éŸ³é¢‘å»¶è¿Ÿé«˜æ€ä¹ˆåŠï¼Ÿ

A: ä¼˜åŒ–éŸ³é¢‘å¤„ç†ï¼š

```dart
// 1. ä½¿ç”¨è¾ƒå°çš„éŸ³é¢‘å—
const chunkDuration = Duration(milliseconds: 20);

// 2. å‡å°‘éŸ³é¢‘æ ¼å¼è½¬æ¢
// ç›´æ¥ä½¿ç”¨ PCM 16bit, 16kHz, mono

// 3. å¯ç”¨ opus å‹ç¼©ï¼ˆå¦‚æœæ”¯æŒï¼‰
```

### Q: å¦‚ä½•å®ç°è¯­éŸ³å”¤é†’ï¼Ÿ

A: ç»“åˆ VADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰ï¼š

```dart
// ä½¿ç”¨ vad åŒ…æ£€æµ‹è¯­éŸ³
import 'package:vad/vad.dart';

final vad = VAD.create(
  mode: VADMode.aggressive,
  sampleRate: 16000,
);

vad.onSpeechStart = () {
  print('ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³');
  _chat?.startListening();
};

vad.onSpeechEnd = () {
  print('ğŸ¤ è¯­éŸ³ç»“æŸ');
  _chat?.stopListening();
};
```

---

## ä¸‹ä¸€æ­¥

- [éŸ³é¢‘å¤„ç†æŒ‡å—](audio.md) - äº†è§£æ›´å¤šéŸ³é¢‘åŠŸèƒ½
- [é”™è¯¯å¤„ç†](../advanced/error-handling.md) - é”™è¯¯å¤„ç†æœ€ä½³å®è·µ
- [æ€§èƒ½ä¼˜åŒ–](../advanced/performance.md) - ä¼˜åŒ–å®æ—¶æ€§èƒ½
